<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Emotion Tracker V2 - Clean Architecture</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            color: white;
        }

        .container {
            max-width: 800px;
            width: 90%;
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            color: #333;
            text-align: center;
        }

        .step {
            display: none;
            animation: fadeIn 0.5s ease-in;
        }

        .step.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        h1 {
            color: #667eea;
            margin-bottom: 20px;
            font-size: 2.5em;
        }

        h2 {
            color: #764ba2;
            margin-bottom: 15px;
            font-size: 1.8em;
        }

        .btn {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 15px 30px;
            border-radius: 50px;
            font-size: 1.1em;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
            min-width: 200px;
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
            transform: none;
        }

        .video-container {
            position: relative;
            width: 100%;
            max-width: 400px;
            margin: 20px auto;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3);
        }

        video {
            width: 100%;
            height: auto;
            display: block;
            pointer-events: none;
        }
        
        /* Completely hide video controls across all browsers */
        video::-webkit-media-controls {
            display: none !important;
        }
        
        video::-webkit-media-controls-panel {
            display: none !important;
        }
        
        video::-webkit-media-controls-play-button {
            display: none !important;
        }
        
        video::-webkit-media-controls-start-playback-button {
            display: none !important;
        }
        
        video::-moz-media-controls {
            display: none !important;
        }
        
        video::-ms-media-controls {
            display: none !important;
        }

        .progress-bar {
            width: 100%;
            height: 8px;
            background: #e0e0e0;
            border-radius: 4px;
            overflow: hidden;
            margin: 20px 0;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #667eea, #764ba2);
            width: 0%;
            transition: width 0.3s ease;
        }

        .status {
            padding: 15px;
            margin: 15px 0;
            border-radius: 10px;
            font-weight: bold;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }

        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }

        .debug-panel {
            display: none; /* Hidden from users */
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            max-height: 300px;
            overflow-y: auto;
            text-align: left;
            font-family: monospace;
            font-size: 0.9em;
        }

        .debug-entry {
            margin: 5px 0;
            padding: 3px 0;
            border-bottom: 1px solid #e9ecef;
        }

        .debug-entry:last-child {
            border-bottom: none;
        }

        .completion-code {
            background: #28a745;
            color: white;
            padding: 20px;
            border-radius: 10px;
            font-size: 1.5em;
            font-weight: bold;
            margin: 20px 0;
        }

        @media (max-width: 768px) {
            .container {
                width: 95%;
                padding: 20px;
            }
            
            h1 {
                font-size: 2em;
            }
            
            .btn {
                min-width: 150px;
                font-size: 1em;
            }
            
            /* Mobile-specific styling for video overlay button */
            #videoOverlay {
                font-size: 1em !important;
            }
            
            #videoOverlay button {
                padding: 12px 25px !important;
                font-size: 1em !important;
                min-width: 140px !important;
            }
        }
        
        .question-section {
            margin: 30px 0;
            text-align: left;
        }
        
        .question {
            margin-bottom: 25px;
        }
        
        .question label {
            display: block;
            margin-bottom: 8px;
            font-weight: bold;
            color: #333;
        }
        
        .question textarea {
            width: 100%;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-family: inherit;
            font-size: 16px;
            resize: vertical;
            min-height: 100px;
            box-sizing: border-box;
        }
        
        .question select {
            width: 100%;
            padding: 12px;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-family: inherit;
            font-size: 16px;
            background: white;
            box-sizing: border-box;
        }
        
        .question textarea:focus,
        .question select:focus {
            outline: none;
            border-color: #007bff;
            box-shadow: 0 0 0 3px rgba(0, 123, 255, 0.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <!-- Step 1: System Check -->
        <div class="step active" id="step1">
            <h1>üîç System Check</h1>
            <p>Checking system components and configuration...</p>
            <div class="progress-bar">
                <div class="progress-fill" id="systemProgress"></div>
            </div>
            <div id="systemStatus"></div>
            
            <!-- Video preload status -->
            <div id="preloadStatus" style="display: none; margin: 15px 0; padding: 10px; background: #e3f2fd; border-radius: 8px; font-size: 0.9em; color: #1976d2; text-align: center;">
                <div id="preloadContent">üé¨ Video preloading in background...</div>
            </div>
            
            <div class="debug-panel" id="systemDebug"></div>
        </div>

        <!-- Step 2: Camera Permission -->
        <div class="step" id="step2">
            <h1>üìπ Camera Access</h1>
            <h2>We need camera access to track emotions</h2>
            <p>Your camera feed stays private and is only used for emotion analysis.</p>
            <button class="btn" id="allowCameraBtn">Allow Camera Access</button>
            <div id="cameraStatus"></div>
        </div>

        <!-- Step 3: Face Detection -->
        <div class="step" id="step3">
            <h1>üë§ Face Detection</h1>
            <h2>Please position your face in the camera view</h2>
            <p>We need to detect your face before starting the video task.</p>
            
            <!-- Face Detection Status -->
            <div id="faceDetectionStatus" style="margin: 20px 0; padding: 20px; border-radius: 15px; background: #f8f9fa;">
                <div style="display: flex; align-items: center; justify-content: center; gap: 15px; margin-bottom: 15px;">
                    <div id="faceIndicator" style="width: 60px; height: 60px; border-radius: 50%; background: #dc3545; display: flex; align-items: center; justify-content: center; color: white; font-size: 24px; transition: all 0.3s ease;">
                        ‚ùå
                    </div>
                    <div style="text-align: left;">
                        <div id="faceStatusText" style="font-size: 1.2em; font-weight: bold; color: #dc3545;">No Face Detected</div>
                        <div style="font-size: 0.9em; color: #666;">Please look directly at the camera</div>
                    </div>
                </div>
                <div id="faceInstructions" style="text-align: center; color: #666; font-size: 0.9em;">
                    <p>üì± Ensure good lighting and look directly at the camera</p>
                    <p>üîç Face detection status will update in real-time</p>
                </div>
            </div>
            
            <button class="btn" id="proceedToVideoBtn" disabled style="opacity: 0.5;">Face Detection Required</button>
            <div id="faceDetectionDebug"></div>
        </div>

        <!-- Step 4: Video Playback -->
        <div class="step" id="step4">
            <h1>üé¨ Video Task</h1>
            <h2>Please watch the video carefully</h2>
            
            <!-- Sound Instructions -->
            <div style="background: #fff3cd; border: 1px solid #ffeaa7; border-radius: 10px; padding: 15px; margin: 20px 0; color: #856404;">
                <div style="display: flex; align-items: center; gap: 10px; margin-bottom: 10px;">
                    <div style="font-size: 1.5em;">üîä</div>
                    <div style="font-weight: bold;">Sound Required</div>
                </div>
                <div style="font-size: 0.9em; line-height: 1.4;">
                    <p style="margin: 0 0 8px 0;">‚Ä¢ Please ensure your device sound is <strong>turned ON</strong></p>
                    <p style="margin: 0 0 8px 0;">‚Ä¢ Check that your volume is at a comfortable level</p>
                    <p style="margin: 0;">‚Ä¢ Audio is important for the complete experience</p>
                </div>
            </div>
            
            <div class="video-container">
                <video id="videoPlayer" 
                       preload="auto" 
                       playsinline 
                       webkit-playsinline
                       x-webkit-airplay="deny"
                       controls="false"
                       disableremoteplayback
                       disablepictureinpicture
                       controlslist="nodownload noplaybackrate nofullscreen noremoteplayback"
                       oncontextmenu="return false;"
                       onclick="return false;"
                       ondblclick="return false;"
                       ontouchstart="return false;"
                       style="pointer-events: none; position: relative;">
                    <source src="" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                <!-- Overlay to prevent any video interaction -->
                <div id="videoOverlay" style="
                    position: absolute;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 100%;
                    background: rgba(0,0,0,0.8);
                    display: flex;
                    flex-direction: column;
                    align-items: center;
                    justify-content: center;
                    color: white;
                    font-size: 1.2em;
                    border-radius: 8px;
                    z-index: 100;
                    pointer-events: all;
                    gap: 20px;
                ">
                    <div style="text-align: center; margin-bottom: 15px;">
                        üé¨ Ready to start emotion tracking
                    </div>
                    <div style="text-align: center; margin-bottom: 15px; font-size: 0.9em; color: #ffd700;">
                        üîä Make sure your sound is ON
                    </div>
                    <button id="startVideoBtn" style="
                        background: linear-gradient(45deg, #667eea, #764ba2);
                        color: white;
                        border: none;
                        padding: 15px 30px;
                        font-size: 1.1em;
                        border-radius: 25px;
                        cursor: pointer;
                        transition: all 0.3s ease;
                        font-weight: 600;
                        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.4);
                        min-width: 160px;
                        -webkit-tap-highlight-color: transparent;
                        -webkit-touch-callout: none;
                        -webkit-user-select: none;
                        user-select: none;
                        outline: none;
                        touch-action: manipulation;
                    " onmouseover="this.style.transform='translateY(-2px)'; this.style.boxShadow='0 6px 20px rgba(102, 126, 234, 0.6)'" 
                       onmouseout="this.style.transform='translateY(0)'; this.style.boxShadow='0 4px 15px rgba(102, 126, 234, 0.4)'"
                       ontouchstart="this.style.transform='translateY(-1px)'"
                       ontouchend="this.style.transform='translateY(0)'">
                        üöÄ Start Video
                    </button>
                </div>
            </div>
            <div class="progress-bar">
                <div class="progress-fill" id="videoProgress"></div>
            </div>
            <div id="videoStatus"></div>
            
            <!-- Real-time Emotion Data Display -->
            <div id="emotionData" style="display: none; margin-top: 20px; padding: 15px; background: #f8f9fa; border-radius: 10px; text-align: left; font-family: monospace; font-size: 0.9em;">
                <h4 style="margin: 0 0 10px 0; text-align: center;">üìä Real-time Emotion Data</h4>
                <div id="emotionDataContent"></div>
            </div>
        </div>

        <!-- Step 5: Processing -->
        <div class="step" id="step5">
            <h1>‚öôÔ∏è Processing</h1>
            <h2>Processing your emotion data...</h2>
            <div class="progress-bar">
                <div class="progress-fill" id="processingProgress"></div>
            </div>
            <div id="processingStatus"></div>
        </div>

        <!-- Step 6: Questionnaire -->
        <div class="step" id="step6">
            <h1>üìù Quick Survey</h1>
            <h2>Please answer these 2 questions:</h2>
            
            <div class="question-section">
                <div class="question">
                    <label for="question1">1. Please describe the most memorable moment from the video:</label>
                    <textarea id="question1" rows="4" placeholder="What moment stood out to you the most?"></textarea>
                </div>
                
                <div class="question">
                    <label for="question2">2. What is the chance of you will play this game?</label>
                    <select id="question2">
                        <option value="">Select your answer</option>
                        <option value="Very unlikely">Very unlikely</option>
                        <option value="Unlikely">Unlikely</option>
                        <option value="Neutral">Neutral</option>
                        <option value="Likely">Likely</option>
                        <option value="Very likely">Very likely</option>
                    </select>
                </div>
            </div>
            
            <div id="questionnaireStatus" style="margin: 20px 0;"></div>
            
            <button class="btn" id="submitQuestionnaire">Submit & Complete Task</button>
        </div>

        <!-- Step 7: Completion -->
        <div class="step" id="step7">
            <h1>‚úÖ Task Complete</h1>
            <h2>Thank you for participating!</h2>
            <div class="completion-code" id="completionCode"></div>
            <p>Please use this code in your survey platform.</p>
            <div id="dataUploadSection" style="margin: 20px 0;">
                <p style="font-size: 1em; color: #28a745; margin-bottom: 15px;">
                    ‚úÖ Your data has been successfully uploaded to our secure storage.
                </p>
                <p style="font-size: 0.9em; color: #666; margin-top: 10px;">
                    No further action required - your data is safely stored and ready for analysis.
                </p>
            </div>
            <button class="btn" id="restartBtn">Start New Session</button>
        </div>
    </div>

    <script>
        // ==================== CONFIGURATION ====================
        const CONFIG = {
            VIDEO_URL: 'https://assets.homa-cloud.com/cm0wqgm1d002gdslcdl3hq3yl/f4bea092-1f69-4f99-8d7a-fc8fb52ac610/CAY_R91_V1_WW_VID_1080x1920_24s.mp4',
            TASK_ID: 'TASK-CLEAN',
            COMPLETION_CODE: 'CLEAN123',
            MORPHCAST_LICENSE: 'ap95c1923492e8512306644ca7fea0e66e7c27a47b97bb',
            // Fixed Supabase configuration (matching your actual project)
            SUPABASE_URL: 'https://nxlyelvtfphybhyfhxwc.supabase.co', // Your actual project URL
            SUPABASE_KEY: 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im54bHllbHZ0ZnBoeWJoeWZoeHdjIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc1MTYyNzgxOSwiZXhwIjoyMDY3MjAzODE5fQ.8F-la271rAdg-kPuxEySLUDaKyqNItrsoOzwoWWjnbw',   // Your service role key
            VIDEO_DURATION: 24,
            TIMELINE_DURATION: 30,
            // Storage and database configuration
            SUPABASE_STORAGE_BUCKET: 'cay250704',
            SUPABASE_TABLE: 'emotion_tracking_data',  // Fixed table name
            STORAGE_ENDPOINT: 'https://nxlyelvtfphybhyfhxwc.supabase.co/storage/v1/s3',  // Your actual endpoint
            STORAGE_REGION: 'eu-west-3',
            AUTO_UPLOAD: true  // Enable automatic background upload
        };

        // ==================== GLOBAL VARIABLES ====================
        let emotionTracker = null;
        let supabaseClient = null;
        let morphcastWindow = null;
        let trackingData = [];
        let videoStartTime = null;
        let currentStep = 1;
        let systemChecks = {
            morphcast: false,
            supabase: false,
            video: false,
            camera: false
        };
        
        // Real-time emotion data display
        let currentEmotionData = {
            arousal: 0,
            valence: 0,
            attention: 0,
            dominantEmotion: 'neutral',
            faceDetected: false,
            lastUpdate: null
        };
        
        // Store processed data for upload
        let processedReportData = null;
        
        // User ID counter (simple incrementing)
        let currentUserId = null;
        
        // Face detection validation
        let faceDetectionWindow = null;
        let faceDetectionActive = false;
        let lastFaceDetected = false;
        let faceDetectionStartTime = null;

        // ==================== UTILITY FUNCTIONS ====================
        function log(message, type = 'info') {
            const timestamp = new Date().toLocaleTimeString();
            const emoji = {
                'info': '‚ÑπÔ∏è',
                'success': '‚úÖ',
                'warning': '‚ö†Ô∏è',
                'error': '‚ùå',
                'debug': 'üîß'
            }[type] || '‚ÑπÔ∏è';
            
            // Always log to console for debugging
            console.log(`${emoji} [${timestamp}] ${message}`);
            
            // REMOVED: Debug panel display - keep logs only in console
            // No longer showing logs to user interface
        }

        function showStatus(elementId, message, type = 'info') {
            const element = document.getElementById(elementId);
            if (element) {
                element.innerHTML = `<div class="status ${type}">${message}</div>`;
            }
        }
        
        function showDebugStatus(elementId, message, type = 'info') {
            const element = document.getElementById(elementId);
            if (element) {
                element.innerHTML = `<div style="padding: 10px; margin: 10px 0; border-radius: 8px; font-size: 0.9em; background: ${type === 'success' ? '#d4edda' : type === 'error' ? '#f8d7da' : '#d1ecf1'}; color: ${type === 'success' ? '#155724' : type === 'error' ? '#721c24' : '#0c5460'};">${message}</div>`;
            }
        }

        function updateProgress(elementId, percentage) {
            const element = document.getElementById(elementId);
            if (element) {
                element.style.width = `${percentage}%`;
            }
        }

        function showStep(stepNumber) {
            document.querySelectorAll('.step').forEach(step => {
                step.classList.remove('active');
            });
            document.getElementById(`step${stepNumber}`).classList.add('active');
            currentStep = stepNumber;
            log(`Showing step ${stepNumber}`, 'info');
        }

        function generateWorkerId() {
            return 'worker_' + Math.random().toString(36).substr(2, 9);
        }
        
        function updateFaceDetectionDisplay(faceDetected, totalFaces = 0) {
            const faceIndicator = document.getElementById('faceIndicator');
            const faceStatusText = document.getElementById('faceStatusText');
            const proceedBtn = document.getElementById('proceedToVideoBtn');
            
            if (faceDetected) {
                faceIndicator.style.background = '#28a745';
                faceIndicator.innerHTML = '‚úÖ';
                faceStatusText.textContent = `Face Detected (${totalFaces})`;
                faceStatusText.style.color = '#28a745';
                proceedBtn.disabled = false;
                proceedBtn.style.opacity = '1';
                proceedBtn.textContent = 'Start Video Task';
            } else {
                faceIndicator.style.background = '#dc3545';
                faceIndicator.innerHTML = '‚ùå';
                faceStatusText.textContent = 'No Face Detected';
                faceStatusText.style.color = '#dc3545';
                proceedBtn.disabled = true;
                proceedBtn.style.opacity = '0.5';
                proceedBtn.textContent = 'Face Detection Required';
            }
            
            lastFaceDetected = faceDetected;
        }
        
        async function startFaceDetection() {
            try {
                log('Starting face detection validation...', 'info');
                faceDetectionActive = true;
                faceDetectionStartTime = Date.now();
                
                // Initialize Morphcast for face detection
                faceDetectionWindow = await CY.loader()
                    .licenseKey(CONFIG.MORPHCAST_LICENSE)
                    .addModule(CY.modules().FACE_DETECTOR.name, { maxInputFrameSize: 320, smoothness: 0.83 })
                    .load();
                
                log('Face detection initialized', 'success');
                
                // Set up face detection event listener
                window.addEventListener(CY.modules().FACE_DETECTOR.eventName, handleFaceDetectionValidation);
                
                // Start face detection
                await faceDetectionWindow.start();
                
                log('Face detection started - please look at the camera', 'info');
                
            } catch (error) {
                log(`Face detection initialization failed: ${error.message}`, 'error');
                showDebugStatus('faceDetectionDebug', `Face detection error: ${error.message}`, 'error');
                
                // Allow proceeding even if face detection fails
                setTimeout(() => {
                    updateFaceDetectionDisplay(true, 1);
                    log('Face detection bypassed due to error', 'warning');
                }, 2000);
            }
        }
        
        function handleFaceDetectionValidation(evt) {
            if (!faceDetectionActive) return;
            
            const faceDetected = evt.detail.totalFaces > 0;
            const totalFaces = evt.detail.totalFaces;
            
            // Update display
            updateFaceDetectionDisplay(faceDetected, totalFaces);
            
            // Log face detection changes
            if (faceDetected !== lastFaceDetected) {
                log(`Face detection: ${faceDetected ? 'DETECTED' : 'LOST'} (${totalFaces} faces)`, faceDetected ? 'success' : 'warning');
            }
            
            // Debug logging every 2 seconds
            const now = Date.now();
            if (faceDetectionStartTime && (now - faceDetectionStartTime) % 2000 < 100) {
                const elapsed = ((now - faceDetectionStartTime) / 1000).toFixed(1);
                showDebugStatus('faceDetectionDebug', `Face Detection: ${faceDetected ? '‚úÖ' : '‚ùå'} | Faces: ${totalFaces} | Time: ${elapsed}s`, faceDetected ? 'success' : 'info');
            }
        }
        
        async function proceedToVideo() {
            try {
                log('Face detected, proceeding to video...', 'success');
                
                // Stop face detection
                faceDetectionActive = false;
                if (faceDetectionWindow) {
                    await faceDetectionWindow.stop();
                    window.removeEventListener(CY.modules().FACE_DETECTOR.eventName, handleFaceDetectionValidation);
                    
                    // Add delay to ensure complete cleanup
                    await new Promise(resolve => setTimeout(resolve, 1000));
                    faceDetectionWindow = null;
                    
                    log('Face detection validation stopped and cleaned up', 'debug');
                }
                
                // Move to video step
                setupVideo();
                showStep(4);
                
            } catch (error) {
                log(`Error proceeding to video: ${error.message}`, 'error');
            }
        }
        
        function updateEmotionDisplay() {
            const emotionDataDiv = document.getElementById('emotionData');
            const emotionDataContent = document.getElementById('emotionDataContent');
            
            if (!emotionDataDiv || !emotionDataContent) return;
            
            // Show the emotion data display
            emotionDataDiv.style.display = 'block';
            
            const timestamp = new Date().toLocaleTimeString();
            const videoTime = document.getElementById('videoPlayer').currentTime.toFixed(1);
            
            const html = `
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 10px; margin-bottom: 10px;">
                    <div><strong>Video Time:</strong> ${videoTime}s</div>
                    <div><strong>Last Update:</strong> ${timestamp}</div>
                    <div><strong>Face Detected:</strong> ${currentEmotionData.faceDetected ? '‚úÖ Yes' : '‚ùå No'}</div>
                    <div><strong>Data Points:</strong> ${trackingData.length}</div>
                </div>
                <div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 10px; margin-bottom: 10px;">
                    <div><strong>Arousal:</strong> <span style="color: ${currentEmotionData.arousal > 0 ? 'green' : 'red'}">${currentEmotionData.arousal.toFixed(3)}</span></div>
                    <div><strong>Valence:</strong> <span style="color: ${currentEmotionData.valence > 0 ? 'green' : 'red'}">${currentEmotionData.valence.toFixed(3)}</span></div>
                    <div><strong>Attention:</strong> <span style="color: ${currentEmotionData.attention > 0.5 ? 'green' : 'orange'}">${currentEmotionData.attention.toFixed(3)}</span></div>
                </div>
                <div style="text-align: center; margin-top: 10px;">
                    <strong>Dominant Emotion:</strong> 
                    <span style="background: linear-gradient(45deg, #667eea, #764ba2); color: white; padding: 5px 10px; border-radius: 15px; font-size: 0.9em;">
                        ${currentEmotionData.dominantEmotion || 'neutral'}
                    </span>
                </div>
            `;
            
            emotionDataContent.innerHTML = html;
        }

        // ==================== SYSTEM INITIALIZATION ====================
        async function initializeSystem() {
            log('Starting system initialization...', 'info');
            updateProgress('systemProgress', 10);

            // Check 1: Morphcast SDK
            try {
                log('Checking Morphcast SDK availability...', 'debug');
                await loadMorphcastSDK();
                systemChecks.morphcast = true;
                log('Morphcast SDK loaded successfully', 'success');
                updateProgress('systemProgress', 30);
            } catch (error) {
                log(`Morphcast SDK failed: ${error.message}`, 'error');
                showStatus('systemStatus', `Morphcast SDK Error: ${error.message}`, 'error');
                return false;
            }

            // Check 2: Supabase
            try {
                log('Initializing Supabase client...', 'debug');
                await initializeSupabase();
                systemChecks.supabase = true;
                log('Supabase client initialized successfully', 'success');
                updateProgress('systemProgress', 50);
            } catch (error) {
                log(`Supabase initialization failed: ${error.message}`, 'error');
                showStatus('systemStatus', `Supabase Error: ${error.message}`, 'error');
                return false;
            }

            // Check 3: Video
            try {
                log('Testing video loading...', 'debug');
                await testVideoLoading();
                systemChecks.video = true;
                log('Video loading test successful', 'success');
                updateProgress('systemProgress', 70);
            } catch (error) {
                log(`Video loading failed: ${error.message}`, 'error');
                showStatus('systemStatus', `Video Error: ${error.message}`, 'error');
                return false;
            }

            // Check 4: Camera capability
            try {
                log('Checking camera availability...', 'debug');
                await checkCameraCapability();
                systemChecks.camera = true;
                log('Camera capability confirmed', 'success');
                updateProgress('systemProgress', 90);
            } catch (error) {
                log(`Camera check failed: ${error.message}`, 'error');
                showStatus('systemStatus', `Camera Error: ${error.message}`, 'error');
                return false;
            }

            updateProgress('systemProgress', 100);
            showStatus('systemStatus', 'All system checks passed! Ready to proceed.', 'success');
            
            setTimeout(() => {
                log('System initialization complete', 'success');
                showStep(2);
            }, 1000);

            return true;
        }

        async function loadMorphcastSDK() {
            return new Promise((resolve, reject) => {
                if (window.CY && window.CY.loader) {
                    log('Morphcast SDK already loaded', 'debug');
                    resolve();
                    return;
                }

                const script = document.createElement('script');
                script.src = `https://ai-sdk.morphcast.com/v1.16/ai-sdk.js?t=${Date.now()}`;
                script.onload = () => {
                    log('Morphcast SDK script loaded', 'debug');
                    // Wait for SDK to initialize
                    setTimeout(() => {
                        if (window.CY && window.CY.loader) {
                            log('Morphcast SDK initialized', 'debug');
                            resolve();
                        } else {
                            reject(new Error('SDK loaded but CY.loader not available'));
                        }
                    }, 1000);
                };
                script.onerror = () => {
                    reject(new Error('Failed to load Morphcast SDK script'));
                };
                document.head.appendChild(script);
            });
        }

        async function initializeSupabase() {
            return new Promise((resolve, reject) => {
                if (window.supabase) {
                    log('Supabase already loaded', 'debug');
                    supabaseClient = window.supabase.createClient(CONFIG.SUPABASE_URL, CONFIG.SUPABASE_KEY);
                    resolve();
                    return;
                }

                const script = document.createElement('script');
                script.src = 'https://unpkg.com/@supabase/supabase-js@2';
                script.onload = () => {
                    log('Supabase script loaded', 'debug');
                    if (window.supabase) {
                        supabaseClient = window.supabase.createClient(CONFIG.SUPABASE_URL, CONFIG.SUPABASE_KEY);
                        log('Supabase client created', 'debug');
                        resolve();
                    } else {
                        reject(new Error('Supabase script loaded but window.supabase not available'));
                    }
                };
                script.onerror = () => {
                    reject(new Error('Failed to load Supabase script'));
                };
                document.head.appendChild(script);
            });
        }

        async function testVideoLoading() {
            return new Promise((resolve, reject) => {
                // Show preload status
                const preloadStatus = document.getElementById('preloadStatus');
                const preloadContent = document.getElementById('preloadContent');
                if (preloadStatus) {
                    preloadStatus.style.display = 'block';
                    preloadContent.textContent = 'üé¨ Video preloading in background...';
                }
                
                const video = document.createElement('video');
                video.muted = true;
                video.preload = 'auto'; // Changed to 'auto' for better preloading
                
                video.onloadedmetadata = () => {
                    log(`Video metadata loaded: ${video.duration}s`, 'debug');
                    
                    // Start buffering the actual video element too
                    const mainVideo = document.getElementById('videoPlayer');
                    if (mainVideo) {
                        mainVideo.src = CONFIG.VIDEO_URL;
                        mainVideo.preload = 'auto';
                        mainVideo.load();
                        log('Main video started preloading', 'debug');
                        
                        // Update preload status
                        if (preloadContent) {
                            preloadContent.textContent = 'üé¨ Video loaded, buffering for smooth playback...';
                        }
                    }
                    
                    resolve();
                };
                
                video.oncanplaythrough = () => {
                    log('Video can play through (fully buffered)', 'debug');
                    if (preloadContent) {
                        preloadContent.textContent = '‚úÖ Video fully buffered and ready!';
                    }
                };
                
                video.onerror = () => {
                    if (preloadContent) {
                        preloadContent.textContent = '‚ùå Video failed to load';
                    }
                    reject(new Error('Video failed to load'));
                };
                
                video.src = CONFIG.VIDEO_URL;
                
                // Timeout after 15 seconds (increased)
                setTimeout(() => {
                    if (preloadContent) {
                        preloadContent.textContent = '‚è∞ Video loading timeout';
                    }
                    reject(new Error('Video loading timeout'));
                }, 15000);
            });
        }

        async function checkCameraCapability() {
            return new Promise((resolve, reject) => {
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    reject(new Error('Camera not supported by browser'));
                    return;
                }
                
                navigator.mediaDevices.getUserMedia({ video: true })
                    .then(stream => {
                        log('Camera access test successful', 'debug');
                        // Stop the test stream
                        stream.getTracks().forEach(track => track.stop());
                        resolve();
                    })
                    .catch(error => {
                        reject(new Error(`Camera access failed: ${error.message}`));
                    });
            });
        }

        // ==================== CAMERA HANDLING ====================
        async function requestCameraAccess() {
            try {
                log('Requesting camera access...', 'info');
                showStatus('cameraStatus', 'Requesting camera permission...', 'info');
                
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                log('Camera access granted', 'success');
                
                // Stop the stream immediately - we just needed permission
                stream.getTracks().forEach(track => track.stop());
                
                showStatus('cameraStatus', 'Camera access granted successfully!', 'success');
                
                setTimeout(() => {
                    log('Moving to face detection step', 'info');
                    showStep(3);
                    startFaceDetection();
                }, 1000);
                
            } catch (error) {
                log(`Camera access failed: ${error.message}`, 'error');
                showStatus('cameraStatus', `Camera access failed: ${error.message}`, 'error');
            }
        }

        // ==================== VIDEO HANDLING ====================
        function setupVideo() {
            const video = document.getElementById('videoPlayer');
            const startBtn = document.getElementById('startVideoBtn');
            
            log('Setting up video player...', 'debug');
            
            // Video should already be preloaded from system initialization
            if (!video.src) {
                video.src = CONFIG.VIDEO_URL;
                video.preload = 'auto';
                video.load();
                log('Video source set and loading started', 'debug');
            } else {
                log('Video already preloaded', 'debug');
            }
            
            // Prevent video from playing unless started through our button
            let videoAllowedToPlay = false;
            
            const preventUnauthorizedPlay = (event) => {
                if (!videoAllowedToPlay) {
                    event.preventDefault();
                    event.stopPropagation();
                    video.pause();
                    log('Unauthorized video play attempt blocked', 'warning');
                    return false;
                }
            };
            
            video.addEventListener('play', preventUnauthorizedPlay);
            video.addEventListener('playing', preventUnauthorizedPlay);
            
            // Store reference to allow play when button is clicked
            window.allowVideoPlay = () => {
                videoAllowedToPlay = true;
                video.removeEventListener('play', preventUnauthorizedPlay);
                video.removeEventListener('playing', preventUnauthorizedPlay);
            };
            
            // Video event listeners
            video.onloadedmetadata = () => {
                log(`Video metadata loaded: ${video.duration}s`, 'debug');
                
                // Ensure sound is enabled when video loads
                video.muted = false;
                video.volume = 0.8;
                log('Video sound configuration verified', 'debug');
                
                showStatus('videoStatus', 'Video loaded successfully', 'success');
                startBtn.disabled = false;
            };
            
            video.onloadeddata = () => {
                log('Video data loaded', 'debug');
            };
            
            video.oncanplay = () => {
                log('Video can play', 'debug');
            };
            
            video.oncanplaythrough = () => {
                log('Video can play through (fully buffered)', 'success');
                showStatus('videoStatus', 'Video ready to play', 'success');
            };
            
            video.ontimeupdate = () => {
                if (video.duration > 0) {
                    const progress = (video.currentTime / video.duration) * 100;
                    updateProgress('videoProgress', progress);
                }
            };
            
            // Critical: Pause emotion tracking when video pauses
            video.onpause = () => {
                log('Video paused - pausing emotion tracking', 'warning');
                if (morphcastWindow && videoStartTime) {
                    try {
                        morphcastWindow.pause();
                        log('Emotion tracking paused', 'debug');
                    } catch (error) {
                        log(`Error pausing emotion tracking: ${error.message}`, 'warning');
                    }
                }
                showStatus('videoStatus', 'Video paused', 'warning');
            };
            
            // Critical: Resume emotion tracking when video resumes
            video.onplay = () => {
                log('Video resumed - resuming emotion tracking', 'success');
                if (morphcastWindow && videoStartTime) {
                    try {
                        morphcastWindow.resume();
                        log('Emotion tracking resumed', 'debug');
                    } catch (error) {
                        log(`Error resuming emotion tracking: ${error.message}`, 'warning');
                    }
                }
                
                // Confirm sound is playing
                if (!video.muted && video.volume > 0) {
                    showStatus('videoStatus', 'üîä Video playing with sound - emotion tracking active', 'success');
                } else {
                    showStatus('videoStatus', 'üîá Video playing (muted) - emotion tracking active', 'warning');
                }
            };
            
            video.onended = () => {
                log('Video playback ended', 'success');
                showStatus('videoStatus', 'Video completed successfully!', 'success');
                
                // Exit fullscreen when video ends
                exitFullscreen();
                
                // Clean up event listeners
                cleanupVideoEventListeners();
                
                setTimeout(() => {
                    processEmotionData();
                }, 1000);
            };
            
            video.onerror = () => {
                log(`Video error: ${video.error?.message || 'Unknown error'}`, 'error');
                showStatus('videoStatus', `Video error: ${video.error?.message || 'Unknown error'}`, 'error');
            };
            
            video.onstalled = () => {
                log('Video stalled', 'warning');
                showStatus('videoStatus', 'Video loading... Please wait.', 'warning');
            };
            
            video.onwaiting = () => {
                log('Video waiting for data', 'warning');
                showStatus('videoStatus', 'Buffering... Please wait.', 'warning');
                
                // Pause emotion tracking during buffering
                if (morphcastWindow && videoStartTime) {
                    try {
                        morphcastWindow.pause();
                        log('Emotion tracking paused due to buffering', 'debug');
                    } catch (error) {
                        log(`Error pausing during buffering: ${error.message}`, 'warning');
                    }
                }
            };
            
            video.onplaying = () => {
                log('Video playing', 'success');
                showStatus('videoStatus', 'Video playing successfully', 'success');
                
                // Resume emotion tracking when video plays
                if (morphcastWindow && videoStartTime) {
                    try {
                        morphcastWindow.resume();
                        log('Emotion tracking resumed after buffering', 'debug');
                    } catch (error) {
                        log(`Error resuming after buffering: ${error.message}`, 'warning');
                    }
                }
            };
            
            video.onseeking = () => {
                log('Video seeking', 'debug');
            };
            
            video.onseeked = () => {
                log('Video seek completed', 'debug');
            };
        }

        async function startVideo() {
            const video = document.getElementById('videoPlayer');
            const startBtn = document.getElementById('startVideoBtn');
            const videoOverlay = document.getElementById('videoOverlay');
            
            try {
                log('Starting video playback...', 'info');
                
                // Disable button and show loading state
                if (startBtn) {
                    startBtn.disabled = true;
                    startBtn.innerHTML = '‚è≥ Starting...';
                    startBtn.style.opacity = '0.7';
                    startBtn.style.cursor = 'not-allowed';
                }
                
                showStatus('videoStatus', 'Starting video...', 'info');
                
                // Allow video to play through our controlled process
                if (window.allowVideoPlay) {
                    window.allowVideoPlay();
                }
                
                // Safari-specific: Ensure video is fully loaded before starting
                if (video.readyState < 2) {
                    log('Safari: Waiting for video to load...', 'info');
                    await new Promise((resolve) => {
                        const onCanPlay = () => {
                            video.removeEventListener('canplay', onCanPlay);
                            resolve();
                        };
                        video.addEventListener('canplay', onCanPlay);
                        video.load(); // Force reload for Safari
                    });
                }
                
                // Initialize emotion tracking
                await initializeEmotionTracking();
                
                // Remove the video overlay to show the actual video
                if (videoOverlay) {
                    videoOverlay.style.display = 'none';
                }
                
                // Enable video interactions only when starting properly
                video.style.pointerEvents = 'auto';
                
                // Disable video controls and prevent seeking
                video.controls = false;
                video.addEventListener('seeking', preventSeeking);
                video.addEventListener('seeked', preventSeeking);
                video.addEventListener('contextmenu', preventRightClick);
                
                // Add mobile-specific touch event prevention
                video.addEventListener('touchstart', preventTouch);
                video.addEventListener('touchmove', preventTouch);
                video.addEventListener('touchend', preventTouch);
                
                // Prevent keyboard shortcuts
                document.addEventListener('keydown', preventKeyboardShortcuts);
                
                // Ensure video sound is enabled
                video.muted = false;
                video.volume = 0.8; // Set to 80% volume
                log('Video sound enabled and volume set to 80%', 'info');
                
                // Safari-specific: Try to start video first, then fullscreen
                log('Safari: Starting video play...', 'info');
                await video.play();
                videoStartTime = Date.now();
                
                // Safari-specific: Enter fullscreen after video starts playing
                try {
                    await enterFullscreen(video);
                } catch (fullscreenError) {
                    // Safari may block fullscreen - continue without it
                    log(`Safari: Fullscreen blocked: ${fullscreenError.message}`, 'warning');
                }
                
                // Show real-time emotion data
                document.getElementById('emotionData').style.display = 'block';
                
                log('Video started successfully', 'success');
                
                // Show sound status feedback
                if (!video.muted && video.volume > 0) {
                    showStatus('videoStatus', 'üîä Video playing with sound - emotion tracking active', 'success');
                } else {
                    showStatus('videoStatus', 'üîá Video playing (check sound) - emotion tracking active', 'warning');
                }
                
            } catch (error) {
                log(`Video start failed: ${error.message}`, 'error');
                showStatus('videoStatus', `Failed to start video: ${error.message}`, 'error');
                
                // Restore button state on error
                if (startBtn) {
                    startBtn.disabled = false;
                    startBtn.innerHTML = 'üöÄ Start Video';
                    startBtn.style.opacity = '1';
                    startBtn.style.cursor = 'pointer';
                }
                
                // Re-enable overlay on error
                if (videoOverlay) {
                    videoOverlay.style.display = 'flex';
                }
                video.style.pointerEvents = 'none';
            }
        }
        
        // Fullscreen functionality
        async function enterFullscreen(element) {
            try {
                if (element.requestFullscreen) {
                    await element.requestFullscreen();
                } else if (element.webkitRequestFullscreen) {
                    await element.webkitRequestFullscreen();
                } else if (element.mozRequestFullScreen) {
                    await element.mozRequestFullScreen();
                } else if (element.msRequestFullscreen) {
                    await element.msRequestFullscreen();
                }
                
                // Mobile-specific fullscreen for iOS Safari
                if (element.webkitEnterFullscreen) {
                    element.webkitEnterFullscreen();
                }
                
                log('Entered fullscreen mode', 'debug');
                
            } catch (error) {
                log(`Fullscreen error: ${error.message}`, 'warning');
                // Continue without fullscreen if it fails
            }
        }
        
        // Prevent video seeking/skipping
        function preventSeeking(event) {
            event.preventDefault();
            event.stopPropagation();
            log('Seeking prevented', 'debug');
            
            // Reset video to current time to prevent seeking
            const video = event.target;
            if (video.currentTime !== video.currentTime) {
                video.currentTime = video.currentTime;
            }
            
            return false;
        }
        
        // Prevent right-click context menu
        function preventRightClick(event) {
            event.preventDefault();
            event.stopPropagation();
            return false;
        }
        
        // Prevent touch interactions that could interfere with video
        function preventTouch(event) {
            // Allow single touch for mobile interaction but prevent complex gestures
            if (event.touches && event.touches.length > 1) {
                event.preventDefault();
                event.stopPropagation();
                return false;
            }
        }
        
        // Prevent keyboard shortcuts that could interfere with video
        function preventKeyboardShortcuts(event) {
            const preventedKeys = [
                'Space', 'ArrowLeft', 'ArrowRight', 'ArrowUp', 'ArrowDown',
                'Home', 'End', 'PageUp', 'PageDown', 'Escape'
            ];
            
            if (preventedKeys.includes(event.code) || 
                (event.ctrlKey && ['KeyF', 'KeyR', 'KeyW'].includes(event.code))) {
                event.preventDefault();
                event.stopPropagation();
                log('Keyboard shortcut prevented', 'debug');
                return false;
            }
        }
        
        // Exit fullscreen
        function exitFullscreen() {
            try {
                if (document.exitFullscreen) {
                    document.exitFullscreen();
                } else if (document.webkitExitFullscreen) {
                    document.webkitExitFullscreen();
                } else if (document.mozCancelFullScreen) {
                    document.mozCancelFullScreen();
                } else if (document.msExitFullscreen) {
                    document.msExitFullscreen();
                }
                
                log('Exited fullscreen mode', 'debug');
                
            } catch (error) {
                log(`Exit fullscreen error: ${error.message}`, 'warning');
            }
        }
        
        // Clean up video event listeners
        function cleanupVideoEventListeners() {
            const video = document.getElementById('videoPlayer');
            
            if (video) {
                video.removeEventListener('seeking', preventSeeking);
                video.removeEventListener('seeked', preventSeeking);
                video.removeEventListener('contextmenu', preventRightClick);
                video.removeEventListener('touchstart', preventTouch);
                video.removeEventListener('touchmove', preventTouch);
                video.removeEventListener('touchend', preventTouch);
            }
            
            document.removeEventListener('keydown', preventKeyboardShortcuts);
            
            log('Video event listeners cleaned up', 'debug');
        }

        // ==================== EMOTION TRACKING ====================
        async function initializeEmotionTracking() {
            try {
                log('Initializing emotion tracking...', 'debug');
                
                if (!window.CY || !window.CY.loader) {
                    throw new Error('Morphcast SDK not available');
                }
                
                // Clear any existing instances first
                if (morphcastWindow) {
                    try {
                        await morphcastWindow.stop();
                        log('Stopped existing Morphcast instance', 'debug');
                    } catch (error) {
                        log(`Error stopping existing instance: ${error.message}`, 'warning');
                    }
                    morphcastWindow = null;
                }
                
                // Add additional delay to ensure complete cleanup
                await new Promise(resolve => setTimeout(resolve, 1500));
                
                log('Setting up Morphcast event listeners...', 'debug');
                
                // Set up event listeners for tracking data
                window.addEventListener(CY.modules().FACE_AROUSAL_VALENCE.eventName, (evt) => {
                    if (!videoStartTime) return;
                    
                    const currentTime = Date.now();
                    
                    const dataPoint = {
                        mediaTime: document.getElementById('videoPlayer').currentTime,
                        type: 'FACE_AROUSAL_VALENCE',
                        valence: evt.detail.output.valence,
                        arousal: evt.detail.output.arousal
                    };
                    
                    trackingData.push(dataPoint);
                    
                    // Update real-time display
                    currentEmotionData.arousal = evt.detail.output.arousal;
                    currentEmotionData.valence = evt.detail.output.valence;
                    currentEmotionData.faceDetected = true;
                    currentEmotionData.lastUpdate = currentTime;
                    
                    // Log every 50 data points with current values
                    if (trackingData.length % 50 === 0) {
                        log(`üìä Data: ${trackingData.length} points | Arousal: ${evt.detail.output.arousal.toFixed(3)} | Valence: ${evt.detail.output.valence.toFixed(3)}`, 'debug');
                        updateEmotionDisplay();
                    }
                });

                window.addEventListener(CY.modules().FACE_EMOTION.eventName, (evt) => {
                    if (!videoStartTime) return;
                    
                    const currentTime = Date.now();
                    
                    const dataPoint = {
                        mediaTime: document.getElementById('videoPlayer').currentTime,
                        type: 'FACE_EMOTION',
                        dominantEmotion: evt.detail.output.dominantEmotion,
                        emotions: evt.detail.output.emotion
                    };
                    
                    trackingData.push(dataPoint);
                    
                    // Update real-time display
                    currentEmotionData.dominantEmotion = evt.detail.output.dominantEmotion;
                    currentEmotionData.faceDetected = true;
                    currentEmotionData.lastUpdate = currentTime;
                    
                    // Log emotion changes
                    if (trackingData.length % 25 === 0) {
                        log(`üòä Emotion: ${evt.detail.output.dominantEmotion} | Total: ${trackingData.length}`, 'debug');
                        updateEmotionDisplay();
                    }
                });

                window.addEventListener(CY.modules().FACE_ATTENTION.eventName, (evt) => {
                    if (!videoStartTime) return;
                    
                    const currentTime = Date.now();
                    
                    const dataPoint = {
                        mediaTime: document.getElementById('videoPlayer').currentTime,
                        type: 'FACE_ATTENTION',
                        attention: evt.detail.output.attention
                    };
                    
                    trackingData.push(dataPoint);
                    
                    // Update real-time display
                    currentEmotionData.attention = evt.detail.output.attention;
                    currentEmotionData.faceDetected = true;
                    currentEmotionData.lastUpdate = currentTime;
                    
                    // Log attention updates
                    if (trackingData.length % 75 === 0) {
                        log(`üëÄ Attention: ${evt.detail.output.attention.toFixed(3)} | Total: ${trackingData.length}`, 'debug');
                        updateEmotionDisplay();
                    }
                });

                window.addEventListener(CY.modules().FACE_DETECTOR.eventName, (evt) => {
                    if (!videoStartTime) return;
                    
                    const currentTime = Date.now();
                    
                    const dataPoint = {
                        mediaTime: document.getElementById('videoPlayer').currentTime,
                        type: 'FACE_DETECTOR',
                        totalFaces: evt.detail.totalFaces,
                        status: evt.detail.status
                    };
                    
                    trackingData.push(dataPoint);
                    
                    // Update face detection status
                    currentEmotionData.faceDetected = evt.detail.totalFaces > 0;
                    currentEmotionData.lastUpdate = currentTime;
                    
                    // Log face detection changes
                    if (trackingData.length % 100 === 0) {
                        log(`üë§ Face Detection: ${evt.detail.totalFaces > 0 ? 'Yes' : 'No'} | Total: ${trackingData.length}`, 'debug');
                        updateEmotionDisplay();
                    }
                });
                
                log('Event listeners set up successfully', 'debug');
                
                // Initialize Morphcast with correct API
                log('Loading Morphcast modules...', 'debug');
                
                morphcastWindow = await CY.loader()
                    .licenseKey(CONFIG.MORPHCAST_LICENSE)
                    .addModule(CY.modules().FACE_AROUSAL_VALENCE.name, { smoothness: 0.70 })
                    .addModule(CY.modules().FACE_EMOTION.name, { smoothness: 0.40 })
                    .addModule(CY.modules().FACE_ATTENTION.name, { smoothness: 0.83 })
                    .addModule(CY.modules().FACE_DETECTOR.name, { maxInputFrameSize: 320, smoothness: 0.83 })
                    .addModule(CY.modules().ALARM_NO_FACE.name, { timeWindowMs: 10000, initialToleranceMs: 7000, threshold: 0.75 })
                    .addModule(CY.modules().DATA_AGGREGATOR.name, { initialWaitMs: 2000, periodMs: 1000 })
                    .load();
                
                log('Morphcast modules loaded successfully', 'success');
                
                // Start tracking
                await morphcastWindow.start();
                
                // Set up periodic display updates
                const displayUpdateInterval = setInterval(() => {
                    if (videoStartTime && !document.getElementById('videoPlayer').paused) {
                        updateEmotionDisplay();
                    }
                }, 2000); // Update every 2 seconds
                
                // Store interval reference for cleanup
                morphcastWindow.displayUpdateInterval = displayUpdateInterval;
                
                log('Emotion tracking started successfully', 'success');
                
            } catch (error) {
                log(`Emotion tracking initialization failed: ${error.message}`, 'error');
                throw error;
            }
        }

        // ==================== DATA PROCESSING ====================
        async function processEmotionData() {
            showStep(5);
            
            try {
                log('Processing emotion data...', 'info');
                showStatus('processingStatus', 'Processing emotion data...', 'info');
                updateProgress('processingProgress', 20);
                
                if (trackingData.length === 0) {
                    throw new Error('No tracking data collected');
                }
                
                log(`Processing ${trackingData.length} data points`, 'debug');
                
                // Generate worker ID
                const workerId = generateWorkerId();
                
                // Prepare data for storage
                const reportData = {
                    workerId: workerId,
                    taskId: CONFIG.TASK_ID,
                    timestamp: Date.now(),
                    videoUrl: CONFIG.VIDEO_URL,
                    videoDuration: CONFIG.VIDEO_DURATION,
                    trackingData: trackingData,
                    summary: generateSummary(trackingData)
                };
                
                // Store for download
                processedReportData = reportData;
                
                updateProgress('processingProgress', 80);
                showStatus('processingStatus', 'Preparing data for upload...', 'info');
                
                // Data will be uploaded after questionnaire is completed
                log('Data processing complete, moving to questionnaire', 'info');
                
                updateProgress('processingProgress', 80);
                
                // Clean up
                if (morphcastWindow) {
                    await morphcastWindow.stop();
                    
                    // Stop display update interval
                    if (morphcastWindow.displayUpdateInterval) {
                        clearInterval(morphcastWindow.displayUpdateInterval);
                        log('Display update interval stopped', 'debug');
                    }
                    
                    log('Morphcast tracking stopped', 'debug');
                }
                
                updateProgress('processingProgress', 100);
                showStatus('processingStatus', 'Data processing completed successfully!', 'success');
                
                setTimeout(() => {
                    showQuestionnaire();
                }, 1000);
                
            } catch (error) {
                log(`Data processing failed: ${error.message}`, 'error');
                showStatus('processingStatus', `Processing failed: ${error.message}`, 'error');
            }
        }

        function generateSummary(data) {
            if (data.length === 0) return {};
            
            // Group by data type
            const arousalValenceData = data.filter(d => d.type === 'FACE_AROUSAL_VALENCE');
            const emotionData = data.filter(d => d.type === 'FACE_EMOTION');
            const attentionData = data.filter(d => d.type === 'FACE_ATTENTION');
            const detectorData = data.filter(d => d.type === 'FACE_DETECTOR');
            
            // Calculate face detection rate from detector data
            const faceDetectedCount = detectorData.filter(d => d.totalFaces > 0).length;
            const faceDetectionRate = detectorData.length > 0 ? (faceDetectedCount / detectorData.length) * 100 : 0;
            
            const summary = {
                totalDataPoints: data.length,
                faceDetectionRate: faceDetectionRate,
                dataTypes: {
                    arousalValence: arousalValenceData.length,
                    emotion: emotionData.length,
                    attention: attentionData.length,
                    detector: detectorData.length
                }
            };
            
            // Calculate averages if data exists
            if (arousalValenceData.length > 0) {
                summary.averageArousal = arousalValenceData.reduce((sum, d) => sum + (d.arousal || 0), 0) / arousalValenceData.length;
                summary.averageValence = arousalValenceData.reduce((sum, d) => sum + (d.valence || 0), 0) / arousalValenceData.length;
            }
            
            if (attentionData.length > 0) {
                summary.averageAttention = attentionData.reduce((sum, d) => sum + (d.attention || 0), 0) / attentionData.length;
            }
            
            if (emotionData.length > 0) {
                const dominantEmotions = emotionData.map(d => d.dominantEmotion).filter(e => e);
                summary.dominantEmotions = [...new Set(dominantEmotions)];
                
                // Calculate average emotion scores
                const emotionTotals = {
                    Angry: 0, Disgust: 0, Fear: 0, Happy: 0, 
                    Neutral: 0, Sad: 0, Surprise: 0
                };
                
                emotionData.forEach(d => {
                    if (d.emotions) {
                        Object.keys(emotionTotals).forEach(emotion => {
                            if (d.emotions[emotion] !== undefined) {
                                emotionTotals[emotion] += d.emotions[emotion];
                            }
                        });
                    }
                });
                
                summary.averageEmotions = {};
                Object.keys(emotionTotals).forEach(emotion => {
                    summary.averageEmotions[emotion] = emotionTotals[emotion] / emotionData.length;
                });
            }
            
            return summary;
        }

        // Legacy saveToSupabase function removed - now using storage upload + database record

        // ==================== QUESTIONNAIRE ====================
        function showQuestionnaire() {
            // Exit fullscreen when moving to questionnaire
            try {
                if (document.fullscreenElement) {
                    document.exitFullscreen().catch(err => {
                        log(`Error exiting fullscreen: ${err.message}`, 'warning');
                    });
                    log('Exited fullscreen mode', 'debug');
                }
            } catch (error) {
                log(`Fullscreen exit failed: ${error.message}`, 'warning');
            }
            
            showStep(6);
            log('Showing questionnaire', 'info');
        }
        
        async function submitQuestionnaire() {
            try {
                const question1 = document.getElementById('question1').value.trim();
                const question2 = document.getElementById('question2').value;
                
                // Validate answers
                if (!question1) {
                    showStatus('questionnaireStatus', 'Please answer the first question', 'error');
                    return;
                }
                
                if (!question2) {
                    showStatus('questionnaireStatus', 'Please select an answer for the second question', 'error');
                    return;
                }
                
                showStatus('questionnaireStatus', 'Submitting answers and uploading data...', 'info');
                
                // Generate user ID
                currentUserId = await getNextUserId();
                
                // Create filename for JSON
                const filename = `emotion_data_user_${currentUserId}_${Date.now()}.json`;
                
                // Upload JSON to Supabase Storage (with retry)
                const uploadResult = await uploadWithRetry(processedReportData, filename);
                
                if (uploadResult) {
                    // Create database record
                    await createUserRecord(currentUserId, filename, question1, question2);
                    
                    showStatus('questionnaireStatus', 'Successfully submitted!', 'success');
                    
                    setTimeout(() => {
                        showCompletion();
                    }, 1000);
                } else {
                    throw new Error('Failed to upload data');
                }
                
            } catch (error) {
                log(`Questionnaire submission failed: ${error.message}`, 'error');
                showStatus('questionnaireStatus', `Submission failed: ${error.message}`, 'error');
            }
        }
        
        async function getNextUserId() {
            try {
                const { data, error } = await supabaseClient
                    .from(CONFIG.SUPABASE_TABLE)
                    .select('user_id')
                    .order('user_id', { ascending: false })
                    .limit(1);
                
                if (error) throw error;
                
                if (data && data.length > 0) {
                    return data[0].user_id + 1;
                } else {
                    return 1; // First user
                }
            } catch (error) {
                log(`Failed to get next user ID: ${error.message}`, 'warning');
                return Math.floor(Math.random() * 10000) + 1; // Fallback to random ID
            }
        }
        
        async function uploadToSupabaseStorage(data, filename) {
            try {
                if (!supabaseClient) {
                    throw new Error('Supabase client not initialized');
                }
                
                // Convert data to JSON string (using V1 pattern)
                const jsonData = JSON.stringify(data, null, 2);
                const fileBlob = new Blob([jsonData], { type: 'application/json' });
                
                // Check file size (V1 pattern)
                if (fileBlob.size > 5 * 1024 * 1024) {
                    throw new Error('File too large (>5MB)');
                }
                
                log(`Uploading ${filename} to bucket: ${CONFIG.SUPABASE_STORAGE_BUCKET}`, 'debug');
                
                // Upload to Supabase Storage (using V1 working pattern)
                const { data: uploadData, error } = await supabaseClient.storage
                    .from(CONFIG.SUPABASE_STORAGE_BUCKET)
                    .upload(filename, fileBlob, {
                        cacheControl: '3600',
                        contentType: 'application/json',
                        upsert: true  // Fixed: V1 uses upsert: true
                    });
                
                if (error) {
                    log(`Supabase upload error details: ${JSON.stringify(error)}`, 'error');
                    throw error;
                }
                
                log(`JSON file uploaded successfully: ${filename}`, 'success');
                return uploadData;
                
            } catch (error) {
                log(`Storage upload failed: ${error.message}`, 'error');
                console.error('Supabase upload error:', error);
                throw error;
            }
        }

        // Add retry logic like V1
        async function uploadWithRetry(data, filename, maxRetries = 3) {
            for (let i = 0; i < maxRetries; i++) {
                try {
                    return await uploadToSupabaseStorage(data, filename);
                } catch (error) {
                    log(`Upload attempt ${i + 1} failed: ${error.message}`, 'warning');
                    if (i === maxRetries - 1) throw error;
                    await new Promise(resolve => setTimeout(resolve, 1000 * (i + 1)));
                }
            }
        }
        
        async function createUserRecord(userId, filename, answer1, answer2) {
            try {
                if (!supabaseClient) {
                    throw new Error('Supabase client not initialized');
                }
                
                const { data, error } = await supabaseClient
                    .from(CONFIG.SUPABASE_TABLE)
                    .insert([{
                        user_id: userId,
                        json_filename: filename,
                        question1_memorable_moment: answer1,
                        question2_play_chance: answer2,
                        task_id: CONFIG.TASK_ID,
                        video_url: CONFIG.VIDEO_URL,
                        created_at: new Date().toISOString()
                    }]);
                
                if (error) throw error;
                
                log(`User record created successfully: User ${userId}`, 'success');
                
            } catch (error) {
                log(`Database record creation failed: ${error.message}`, 'error');
                throw error;
            }
        }

        // ==================== COMPLETION ====================
        function showCompletion() {
            showStep(7);
            document.getElementById('completionCode').textContent = CONFIG.COMPLETION_CODE;
            log('Task completed successfully - data uploaded to storage', 'success');
        }
        
        // Download function removed - data is now automatically uploaded to database

        async function restartSession() {
            log('Restarting session...', 'info');
            
            // Reset all variables
            trackingData = [];
            videoStartTime = null;
            currentStep = 1;
            processedReportData = null;
            currentEmotionData = {
                arousal: 0,
                valence: 0,
                attention: 0,
                dominantEmotion: 'neutral',
                faceDetected: false,
                lastUpdate: null
            };
            
            // Reset face detection variables
            faceDetectionActive = false;
            lastFaceDetected = false;
            faceDetectionStartTime = null;
            
            // Stop Morphcast if running
            if (morphcastWindow) {
                try {
                    await morphcastWindow.stop();
                    log('Morphcast stopped for restart', 'debug');
                } catch (error) {
                    log(`Error stopping Morphcast: ${error.message}`, 'warning');
                }
                morphcastWindow = null;
            }
            
            // Stop face detection if running
            if (faceDetectionWindow) {
                try {
                    await faceDetectionWindow.stop();
                    window.removeEventListener(CY.modules().FACE_DETECTOR.eventName, handleFaceDetectionValidation);
                    log('Face detection stopped for restart', 'debug');
                } catch (error) {
                    log(`Error stopping face detection: ${error.message}`, 'warning');
                }
                faceDetectionWindow = null;
            }
            
            // Reset video
            const video = document.getElementById('videoPlayer');
            video.pause();
            video.currentTime = 0;
            
            // Reset progress bars
            updateProgress('systemProgress', 0);
            updateProgress('videoProgress', 0);
            updateProgress('processingProgress', 0);
            
            // Reset face detection display
            updateFaceDetectionDisplay(false, 0);
            
            // Clear debug panel
            document.getElementById('systemDebug').innerHTML = '';
            
            // Hide emotion data display
            document.getElementById('emotionData').style.display = 'none';
            
            // Start over
            showStep(1);
            setTimeout(async () => {
                await initializeSystem();
            }, 500);
        }

        // ==================== EVENT LISTENERS ====================
        document.addEventListener('DOMContentLoaded', () => {
            log('DOM loaded, starting system initialization...', 'info');
            
            // Set up event listeners
            document.getElementById('allowCameraBtn').addEventListener('click', requestCameraAccess);
            document.getElementById('proceedToVideoBtn').addEventListener('click', proceedToVideo);
            
            // Safari-compatible event listeners for start video button
            const startVideoBtn = document.getElementById('startVideoBtn');
            startVideoBtn.addEventListener('click', startVideo);
            startVideoBtn.addEventListener('touchstart', startVideo, { passive: false });
            
            document.getElementById('submitQuestionnaire').addEventListener('click', submitQuestionnaire);
            document.getElementById('restartBtn').addEventListener('click', async () => {
                await restartSession();
            });
            
            // Start system initialization
            initializeSystem();
        });

        // ==================== ERROR HANDLING ====================
        window.addEventListener('error', (event) => {
            log(`Global error: ${event.error?.message || event.message}`, 'error');
        });

        window.addEventListener('unhandledrejection', (event) => {
            log(`Unhandled rejection: ${event.reason}`, 'error');
        });

    </script>
</body>
</html>

